
---
title: "STAT340 HW10: Prediction III, logistic regression"
author: Jeffrey Hui
date: "November 2022"
output: html_document
---

***

TODO: If you worked with any other students on this homework, please list their names and NetIDs here.

***

## Instructions

Update the "author" and "date" fields in the header and
complete the exercises below.
Knit the document, and submit **both the HTML and RMD** files to Canvas.

__Due date:__ December 1, 2022 at 11:59pm.

---

This homework will review our discussion of logistic regression from this week's lectures.

## 1) Interpreting logistic regression

Suppose we collect data for a group of students in a statistics class with independent variables $X_{1}=\text{hours studied}$, $X_{2}=\text{GPA}$, and binary response variable
$$
Y= \begin{cases} 1 &\mbox{ if student received an A} \\
  0 &\mbox{ otherwise. }
  \end{cases}
$$
Suppose that we fit a logistic regression model to the data, predicting $Y$ from $X_1$ and $X_2$ (and an intercept term) and produce estimated coefficients $\hat{\beta}_{0}=-6, \hat{\beta}_{1}=0.05, \hat{\beta}_{2}=1$.

### Part a) Logistic regression and probability

According to our fitted model, what is the probability that a student receives an A if they study for $40$ hours and have a GPA of $3.5$?

```{r}
sigmoid <- function (x) {
  1 / (1 + exp(-x))
}
sigmoid(40 * 0.05 + 3.5 - 6)
```

The probability is 37.8%.

### Part b) Interpreting coefficients
According to our fitted model, an additional hour spent studying is associated with *how much* of an increase in the log odds of receiving an A?

```{r}
# An additional hour spent studying is associated with 0.05 increase in the log odds of receiving an A.
```

### Part c) "Inverting" logistic regression probabilities
According to our fitted model, how many hours would the student in Part (a) need to study to have a $50\%$ chance of getting an A in the class?
That is, keeping GPA fixed at $3.5$, how many hours of study are needed so that the probability of an A is $50\%$?
If you aren't up for the math, feel free to find an approximate solution via guess-and-check in R.

***

I guessed the hour to get 50, which corresponds to 50% probability to get an A, keeping the GPA fixed at 3.5.

***

```{r}
hour <- 50
sigmoid(.05 * hour + 3.5 - 6)

```

## 2) `mtcars` once again

Let's take yet another look at the `mtcars` data set.
Recall that the columns of this data set are:
```{r}
names(mtcars)
```

The `am` column encodes whether a car is automatic (`0`) or manual (`1`).
Let's build a model to predict whether a car is manual or automatic.

### Part a) Fitting a model

Fit a logistic regression model to regress `am` against the `drat` and `disp` (and an intercept term).

```{r}

logistic <- glm(am ~ 1 + drat + disp, data = mtcars, family = binomial);
summary(logistic)

```

### Part b) Interpreting estimates

Which coefficients (if any) are statistically significantly different from zero at the $\alpha=0.05$ level?
Interpret the meaning of the estimated coefficient(s) that is/are statistically significantly different from zero.

***

The drat coefficient is statistically significantly different from zero since its p-value is less than 0.05. It means that holding other coefficients constant, 1 increase in drat is associated with 4.879 increase in the log odds of a car being manual.

***

### Part c) paring down the model

Choose one of the statistically significant predictors above and re-fit a model using *only* that variable (and an intercept) to predict `am`.
We'll see how to compare the quality of this model to the one from Part (a) when we talk about cross-validation (CV) in upcoming lectures.
For now, compare the estimated coefficient of this variable in both models.
Is there a sizable difference?

Does anything else notable change about the model?

```{r}

logistic2 <- glm(am ~ 1 + drat, data = mtcars, family = binomial);
summary(logistic2)

```

The coefficient changes from 4.879 to 5.577, which there is no sizable difference. The p-value of the coefficient changes to be significantly smaller than the previous.

### Part d) Plotting your findings

Choose one of the statistically significant predictors above.
Use `ggplot2` to plot `am` as a function of this predictor, and overlay a curve describing the logistic regression output when using *only* this predictor to predict `am` (i.e., the model from Part c above).

```{r}
library(ggplot2)

pp <- ggplot(mtcars, aes(x=drat, y=am)) + geom_point()
pp <- pp + geom_smooth(formula = y ~ 1 + x, se = FALSE, method = 'glm', method.args=list(family = "binomial"))
pp

```